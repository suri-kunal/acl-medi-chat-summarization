{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da868585",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6545b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sectiontagger import SectionTagger\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a835170",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce344507",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading ROUGE, BERTScore, BLEURT from HuggingFace')\n",
    "scorers = {\n",
    "    'rouge': (\n",
    "        evaluate.load('rouge'),\n",
    "        {'use_aggregator': False},\n",
    "        ['rouge1', 'rouge2', 'rougeL', 'rougeLsum'],\n",
    "        ['rouge1', 'rouge2', 'rougeL', 'rougeLsum']\n",
    "    ),\n",
    "    'bert_scorer': (\n",
    "        evaluate.load('bertscore'),\n",
    "        {'model_type': 'microsoft/deberta-xlarge-mnli','batch_size':8},\n",
    "        ['precision', 'recall', 'f1'],\n",
    "        ['bertscore_precision', 'bertscore_recall', 'bertscore_f1']\n",
    "    ),\n",
    "    'bleurt': (\n",
    "        evaluate.load('bleurt', config_name='BLEURT-20'),\n",
    "        {},\n",
    "        ['scores'],\n",
    "        ['bleurt']\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd18ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_aggregate(obj, indices):\n",
    "\n",
    "    agg_obj = {}\n",
    "    for k, v in obj.items():\n",
    "        agg_obj[k] = float(np.mean([v[i] for i in indices]))\n",
    "    return agg_obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f486d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_path = Path.cwd().joinpath(\"baseline_model_summaries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea8d540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def faithfullness_check(summary,full_text,max_length):\n",
    "    faithful_tokenizer = \\\n",
    "    AutoTokenizer.from_pretrained(\"CogComp/bart-faithful-summary-detector\")\n",
    "    faithful_model = \\\n",
    "    AutoModelForSequenceClassification.from_pretrained(\"CogComp/bart-faithful-summary-detector\")\n",
    "    faithful_model = faithful_model.to(device)\n",
    "    \n",
    "    test_pair = \\\n",
    "    faithful_tokenizer(text=summary, \\\n",
    "                       text_pair=full_text, \\\n",
    "                       return_tensors='pt', \\\n",
    "                       max_length=max_length, \\\n",
    "                       padding=\"max_length\", \\\n",
    "                       truncation=True)\n",
    "    test_pair = test_pair.to(device)\n",
    "    faithful_score = faithful_model(**test_pair).logits.detach().cpu().numpy().squeeze(0)\n",
    "    return  faithful_score[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da2c89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculating_similarity(summary_list):\n",
    "    embedding_dict = {}\n",
    "    for i,summary in enumerate(summary_list):\n",
    "        embeddings = sentence_model.encode(summary,convert_to_tensor=True)\n",
    "        embeddings = embeddings.detach().cpu()\n",
    "        embedding_dict[i] = embeddings.numpy()\n",
    "\n",
    "    similarity_dict = {}\n",
    "    for model_name_1,embeddings_1 in embedding_dict.items():\n",
    "        similarity_list = []\n",
    "        for model_name_2,embeddings_2 in embedding_dict.items():\n",
    "            if model_name_1 != model_name_2:\n",
    "                cosine_sim = util.cos_sim(embeddings_1,embeddings_2).item()\n",
    "                similarity_list.append(cosine_sim)\n",
    "        avg_cosine_sim = np.mean(similarity_list)\n",
    "        similarity_dict[model_name_1] = avg_cosine_sim\n",
    "    return similarity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e039544",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in baseline_path.glob(\"*.csv\"):\n",
    "    if \"model_summaries\" in f.stem:\n",
    "        preds_df = pd.read_csv(f)\n",
    "        model_prefix = \"suryakiran786/5-fold-stratified-cv-\"\n",
    "        model_name_list = \\\n",
    "        [col for col in preds_df.columns if model_prefix in col]\n",
    "        \n",
    "        if preds_df[\"ID\"].nunique() != preds_df.shape[0]:\n",
    "            raise Exception(\"preds_df has duplicate entries\")\n",
    "        \n",
    "        for idx in preds_df[\"ID\"].unique():\n",
    "            \n",
    "            import pdb\n",
    "            pdb.set_trace()\n",
    "            \n",
    "            dialogue_wo_whitespaces = \\\n",
    "            preds_df.loc[preds_df[\"ID\"] == idx,\"dialogue_wo_whitespaces\"]\n",
    "            predicted_summary_list = \\\n",
    "            preds_df.loc[preds_df[\"ID\"] == idx,model_name_list].values.tolist()\n",
    "            similarity_dict = \\\n",
    "            calculating_similarity(predicted_summary_list)\n",
    "\n",
    "            model_name_list,similarity_list = zip(*similarity_dict.items())\n",
    "\n",
    "            best_similarity_index = np.argmax(similarity_list)\n",
    "            best_summary = predicted_summary_list[best_similarity_index]\n",
    "            preds_df.loc[idx,\"best_summary\"] = best_summary\n",
    "            \n",
    "            faithfullness_dict = {}\n",
    "            for idx,summary in enumerate(predicted_summary_list):\n",
    "                faithfullness = faithfullness_check(summary, \\\n",
    "                                                    dialogue_wo_whitespaces, \\\n",
    "                                                    code_config.TASKA_SUMMARY_MAX_TARGET_LENGTH)\n",
    "                faithfullness_dict[idx] = faithfullness\n",
    "            \n",
    "            model_name_list,faithful_list = zip(*faithfullness_dict.items())\n",
    "            \n",
    "            best_faithfulness_index = np.argmax(faithful_list)\n",
    "            faithful_summary = predicted_summary_list[best_faithfulness_index]\n",
    "            preds_df.loc[idx,\"faithful_summary\"] = faithful_summary\n",
    "        \n",
    "        for ensemble_method in [\"best_summary\",\"faithful_summary\"]:\n",
    "            \n",
    "            pdb.set_trace()\n",
    "            references = preds['section_text'].tolist()\n",
    "            predictions = preds[ensemble_method].tolist()\n",
    "            num_test = len(predictions)\n",
    "\n",
    "            all_scores = {}\n",
    "            for name, (scorer, kwargs, keys, save_keys) in tqdm(scorers.items(),desc=\"scorers\"):\n",
    "                scores = scorer.compute(references=references, predictions=predictions, **kwargs)\n",
    "                for score_key, save_key in zip(keys, save_keys):\n",
    "                    all_scores[save_key] = scores[score_key]\n",
    "\n",
    "            cohorts = [\n",
    "                        ('all', list(range(num_test))),\n",
    "                    ]\n",
    "\n",
    "            outputs = {k: filter_and_aggregate(all_scores, idxs) for (k, idxs) in cohorts}\n",
    "\n",
    "            # ###### OUTPUT TO JSON FILE ########\n",
    "            fn_out = f'{ensemble_method}.json'\n",
    "            fn_out_path = baseline_path.joinpath(fn_out)\n",
    "            print(f'Saving results to {fn_out}')\n",
    "            with open(fn_out_path, 'w') as fd:\n",
    "                json.dump(outputs, fd, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
