{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da868585",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d6545b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-15 20:09:42.642301: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-15 20:09:43.609809: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sectiontagger import SectionTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce344507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ROUGE, BERTScore, BLEURT from HuggingFace\n",
      "INFO:tensorflow:Reading checkpoint /root/.cache/huggingface/metrics/bleurt/BLEURT-20/downloads/extracted/cd1c38739d180ae53192201859a058307621534b704c20700072eca17d748c58/BLEURT-20.\n",
      "INFO:tensorflow:Config file found, reading.\n",
      "INFO:tensorflow:Will load checkpoint BLEURT-20\n",
      "INFO:tensorflow:Loads full paths and checks that files exists.\n",
      "INFO:tensorflow:... name:BLEURT-20\n",
      "INFO:tensorflow:... bert_config_file:bert_config.json\n",
      "INFO:tensorflow:... max_seq_length:512\n",
      "INFO:tensorflow:... vocab_file:None\n",
      "INFO:tensorflow:... do_lower_case:None\n",
      "INFO:tensorflow:... sp_model:sent_piece\n",
      "INFO:tensorflow:... dynamic_seq_length:True\n",
      "INFO:tensorflow:Creating BLEURT scorer.\n",
      "INFO:tensorflow:Creating SentencePiece tokenizer.\n",
      "INFO:tensorflow:Creating SentencePiece tokenizer.\n",
      "INFO:tensorflow:Will load model: /root/.cache/huggingface/metrics/bleurt/BLEURT-20/downloads/extracted/cd1c38739d180ae53192201859a058307621534b704c20700072eca17d748c58/BLEURT-20/sent_piece.model.\n",
      "INFO:tensorflow:SentencePiece tokenizer created.\n",
      "INFO:tensorflow:Creating Eager Mode predictor.\n",
      "INFO:tensorflow:Loading model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-15 20:09:52.940998: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-15 20:09:52.942962: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:BLEURT initialized.\n"
     ]
    }
   ],
   "source": [
    "print('Loading ROUGE, BERTScore, BLEURT from HuggingFace')\n",
    "scorers = {\n",
    "    'rouge': (\n",
    "        evaluate.load('rouge'),\n",
    "        {'use_aggregator': False},\n",
    "        ['rouge1', 'rouge2', 'rougeL', 'rougeLsum'],\n",
    "        ['rouge1', 'rouge2', 'rougeL', 'rougeLsum']\n",
    "    ),\n",
    "    'bert_scorer': (\n",
    "        evaluate.load('bertscore'),\n",
    "        {'model_type': 'microsoft/deberta-xlarge-mnli','batch_size':8},\n",
    "        ['precision', 'recall', 'f1'],\n",
    "        ['bertscore_precision', 'bertscore_recall', 'bertscore_f1']\n",
    "    ),\n",
    "    'bleurt': (\n",
    "        evaluate.load('bleurt', config_name='BLEURT-20'),\n",
    "        {},\n",
    "        ['scores'],\n",
    "        ['bleurt']\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfd18ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_aggregate(obj, indices):\n",
    "\n",
    "    agg_obj = {}\n",
    "    for k, v in obj.items():\n",
    "        agg_obj[k] = float(np.mean([v[i] for i in indices]))\n",
    "    return agg_obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f486d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_path = Path.cwd().joinpath(\"baseline_model_summaries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e039544",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scorers: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [10:53<00:00, 217.98s/it]\n",
      "scorers: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [10:30<00:00, 210.11s/it]\n",
      "scorers: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [10:27<00:00, 209.27s/it]\n"
     ]
    }
   ],
   "source": [
    "for f in baseline_path.glob(\"*.csv\"):\n",
    "    if \"model_summaries\" in f.stem:\n",
    "        preds_df = pd.read_csv(f)\n",
    "        model_prefix = \"suryakiran786/5-fold-stratified-cv-\"\n",
    "        model_name_list = \\\n",
    "        [col for col in preds_df.columns if model_prefix in col]\n",
    "        \n",
    "        for model_name in model_name_list:\n",
    "            \n",
    "            preds_subset = preds_df[[\"ID\",\"section_text\",model_name]]\n",
    "            \n",
    "            references = preds_subset['section_text'].tolist()\n",
    "            predictions = preds_subset[model_name].tolist()\n",
    "            num_test = len(predictions)\n",
    "\n",
    "            all_scores = {}\n",
    "            for name, (scorer, kwargs, keys, save_keys) in tqdm(scorers.items(),desc=\"scorers\"):\n",
    "                scores = scorer.compute(references=references, predictions=predictions, **kwargs)\n",
    "                for score_key, save_key in zip(keys, save_keys):\n",
    "                    all_scores[save_key] = scores[score_key]\n",
    "\n",
    "            cohorts = [\n",
    "                        ('all', list(range(num_test))),\n",
    "                    ]\n",
    "\n",
    "            outputs = {k: filter_and_aggregate(all_scores, idxs) for (k, idxs) in cohorts}\n",
    "\n",
    "            # ###### OUTPUT TO JSON FILE ########\n",
    "            fn_out = f'{col.split(\"/\")[-1]}.json'\n",
    "            fn_out_path = baseline_path.joinpath(fn_out)\n",
    "            print(f'Saving results to {fn_out}')\n",
    "            with open(fn_out_path, 'w') as fd:\n",
    "                json.dump(outputs, fd, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
